---
title: "Untrusted Servers"
author: "Martí Barri and Ismael López"
date: "6/1/2019"
output: html_document
---
# Análisis de respuestas HTTP y de sus servidores

## Resumen
Este informe se centra en realiza un estudio de los tipos de servidores que estan ofreciendo respuesta por protocolos no seguro. 
En la próxima versión de este documento intentaremos relacionar los servidores con sus posibles vulnerabilidades, pero esta versión ha sido desestimado por falta de tiempo.

Todo los datos han sido obtenidos de fuentes publicas y el análisis corresponde a la situación en que nos encontrabamos a día 22-04-2019. 

Adjuntamos el detalle de los enlaces:

- [HTTP GET Responses](https://opendata.rapid7.com/sonar.http/)
- [MaxMind IP Geolocation](https://dev.maxmind.com/geoip/geoip2/geolite2/)

## Objetivos 

El objetivo de este análisis se centra en responder las siguientes preguntas:

- ¿Dónde estan ubicados los servidores que estan dando servicio por procolos no seguros?
- ¿Qué tipo de servidores son?
- ¿Los paises desarollados son más seguros a nivel de seguridad informatica que los subdesarollados?


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
# Definimos el directorio de trabajo

# ".." is used because getwd() is executed inside vignettes directory
knitr::opts_knit$set(root.dir = file.path(getwd(), ".."))
verbose <- FALSE
```


```{r load_packages, echo = FALSE, cache = TRUE, message = FALSE, include = FALSE}
# Required Packages
pkg <- c("R.utils", "iptools", "parallel", "dplyr", "jsonlite", "GroupAssignmentPackage", "mapproj", "kableExtra", "ggplot2", "leaflet", "net.security", "RColorBrewer")

# Instalar paquetes que no esten instalados
new.pkg <- pkg[!(pkg %in% installed.packages())]
if (length(new.pkg)) 
{
    install.packages(new.pkg)  
}
# Load packages
lapply(pkg, require, character.only = TRUE)
```

## Análisis

Podemos descargar el fichero directamente de la web, muestras del puerto 80, no obstante este fichero descomprimido ocupa 170,70 GB y tardariamos horas en porderlo procesar integramente. Por ello hemos considerado trabajar con una parte significativa de las muestras.

Para generar nuestro archivo de pruebas realizamos las siguentes comando:

`user@linux$ head -n 5000  2019-04-22-1555944117-http_get_80.json > sample80_5kjson`

Convertimos el fichero json en un dataframe, utilizando los siguiente comandos:

```{r sample, echo=TRUE, eval=FALSE}
sample.file <- file.path(getwd(), "data", "sample80_5k.json")
lines <- readLines(sample.file)
df.raw <- plyr::ldply(lines, function(x) as.data.frame(jsonlite::fromJSON(x), stringsAsFactors = FALSE))
saveRDS(object = df.raw, file = file.path(getwd(), "data", "df_http_get_80_raw_5k.rds"))
```

Si observamos detenidamente el fichero que con las muestras, podemos apreciar que la columan "data" tiene los datos cifrados en base64 y que algunas columnas tienen el contedido duplicado o no nos aporta ninguna información relevante para el analisis que queremos realizar. 

Por ello descartamos la informacion de la columna ("host", "vhost" y "path").

La información del dataframe que nos interesa es la siguiente:

```{r load_response_data, echo = FALSE, cache = TRUE}
source.file <- "df_http_get_80_raw_5k.rds"
source.file.geo <- "df_http_get_80_raw_geo_5k.rds"
df.raw <- readRDS(file.path(getwd(), "data", source.file))
df.raw[which(names(df.raw) == "host")] <- NULL
df.raw[which(names(df.raw) == "vhost")] <- NULL
df.raw[which(names(df.raw) == "path")] <- NULL
str(df.raw)
```

## Geolocalización

Procedemos a cargar o descargar el fichero Maxmind, con los siguiente comandos:

```{r load_maxmind, echo = TRUE, cache = TRUE}
# Get maxmind only if pre-computed raw_geo file is not present
if (!file.exists(file.path(getwd(), "data", source.file.geo))) {
  if ((!file.exists(file.path(getwd(), "data", "GeoLite2-City-Blocks-IPv4.csv")))) {
    df.maxmind <- GroupAssignmentPackage::get.maxmind(verbose)
  } else {
    maxmind.source <- file.path(getwd(), "data", "GeoLite2-City-Blocks-IPv4.csv")
    df.maxmind <- read.csv(maxmind.source, stringsAsFactors = FALSE)
  }
  # Expanding MaxMind network ranges
  df.maxmind <- cbind(df.maxmind, iptools::range_boundaries(df.maxmind$network))
  df.maxmind$rowname <- as.integer(row.names(df.maxmind))
}
```

En el fichero Maxmind obtenemos geolocalización de un rango de IP y por lado en el fichero de df_http_get_80_raw_5k.rds tenemos una única IP, el objetivo de este apartado es conseguir la geolocalización de esa IP. 

Para poder comparar en que rango de IP cae esa IP y obtener la geolocalización, convertimos las IP en una variable numérica y vamos iterando hasta encontrar el rango en que IP en que la muestra sea mayor o igual al valor minimo y a su vez sea mas pequeña o igual al valor máximo.

Al realizar esta iteración se consumen mucho tiempo, por ello hemos intentado paralelizar estas operaciones por cada uno de los procesadores que tenemos disponibles en la maquina.

El fichero resultmate de todas estas iteraciones es el siguiente:

```{r geolocate, echo = FALSE, cache = TRUE}
if (!file.exists(file.path(getwd(), "data", source.file.geo))){
  df.raw <- GroupAssignmentPackage::add.numeric.ip(df.raw, "ip")
  df.raw.geo <- GroupAssignmentPackage::geolocate.http.responses(df.maxmind, df.raw)
} else {
  df.raw.geo <- readRDS(file.path(getwd(), "data", source.file.geo))
}
rm(df.raw)
str(df.raw.geo)
```

Como se puede apreciar hemos juntado la parte del maxmaind que nos aporta datos de la geolocalizacion (latiude, longitude, accuracy_radius) al fichero de muestras que teneiamos incialmente.

Una vez aplicado todo el procesamiento y tratamiento de datos, es hora de mostrar los resultados. 

Representando esta información con un gráfico de dispersión podemos ver que la distribución se asemeja notablemente al mapamundi:
```{r dispersion_coord, echo = FALSE, cache = TRUE, fig.align = 'center', warning = FALSE}
library(ggplot2)
# Creamos ggplot con los datos de symantec
gg <- ggplot(data = df.raw.geo, aes(x = longitude, y = latitude)) 
# definimos la grafica por puntos con transparencia
gg <- gg + geom_point(size=1, color="#000099", alpha=1/40) 
# Titulos de los ejes
gg <- gg + xlab("Longitud") + ylab("Latitud")
# aplicamos el tema simple
gg <- gg + theme_bw() 
# tarda un poco pq son 800.000 puntos
print(gg)
```

Añadimos información sobre paises y sus fronteras para enriquecer el mapa.
```{r map_simple, echo=FALSE, cache=TRUE, fig.align='center', warning = FALSE}
world <- map_data("world")
# Quitamos el continete Antarctico ya que no aporta informaci?n
# No es nada personal con los pinguinos...
world <- subset(world, world$region!="Antarctica")

gg <- ggplot(data=world, aes(x=long, y=lat))
gg <- gg + geom_path(aes(group=group), colour="gray70")
# La definici?n de la proyeccion representa la "curvatura" del mapa
gg <- gg + coord_map("mercator", xlim=c(-200, 200))
# A?adimos una capa al mapa con la informacion
gg <- gg + geom_point(data = df.raw.geo, aes(longitude, latitude), 
                      colour="#000099", alpha=1/40, size=1)
# Eliminamos texto y le damos un poco de color
gg <- gg + theme(text=element_blank(), 
                 axis.ticks=element_blank(),
                 panel.grid=element_blank(),
                 panel.background=element_rect(color="gray50",
                                               fill="white"))
print(gg)
```


```{r map_simple2, echo=FALSE, cache=TRUE, fig.align='center', warning = FALSE}
m <- leaflet(df.raw.geo) %>% addTiles() %>% addCircles(lng = ~longitude, lat = ~latitude, color = "blue")
m
```

## Decodificación

Después de ver la localización de los servidores, vamos a decodificar los datos y a parsear los headers para obtener información más detallada.
```{r parse_headers, echo=FALSE, cache=TRUE}
df <- GroupAssignmentPackage::parse.headers(df.raw.geo)
```

Hacemos un poco de retrospectiva en la historia para poder entender el siguiente resultado. 

- La versión http/1.0 nacio en (1996)
Se incluia como mejoras como el soporte a algunos verbos como GET, POST y HEAD. 

- La versión http/1.1 nacio en (1999/2000)
Se incluian  verbos GET,POST,PUT,DELETE,etc y la web se empezaba a orientar a recursos (REST), teníamos las cabeceras en las peticiones, etc

En ambas versiones tanto las respuestas como las peticiones se realizan a través de texto plano.

Podemos ver el número de  versiones utilizadas de HTTP y su geolocalización:
```{r kable.version, echo=FALSE, cache=TRUE, fig.align='center'}
count.version <- plyr::count(df$http.version)
names(count.version) <- c("HTTP version", "freq")
#kable(count.version) %>%
#  kable_styling(bootstrap_options = c("striped", "hover", "condensed"))
pie(as.integer(count.version$freq ), count.version$`HTTP version`, col = colorRampPalette(brewer.pal(3,"Dark2"))(length(count.version$freq)), main = "HTTP version")

```

```{r map_version2, echo=FALSE, cache=TRUE, warning = FALSE}
pal <- colorFactor(
  palette = c('blue', 'red'),
  domain = c('HTTP/1.0', 'HTTP/1.1')
)
m <- leaflet(df) %>% addTiles() %>% addCircles(lng = ~longitude, lat = ~latitude, color = ~ifelse(http.version == 'HTTP/1.0', "blue", "red")) %>% addLegend("bottomright", pal = pal, values = c('HTTP/1.0', 'HTTP/1.1'), title = "HTTP version", opacity = 1)
m
```

También podemos ver los tipos de respuesta:
```{r kable.status, echo=FALSE, cache=TRUE, fig.align='center'}
http.status.number <- sapply(df$http.status, function(x) unlist(strsplit(x, " ", useBytes = TRUE))[2])
http.status.number <- plyr::count(http.status.number)
ordered.status <- http.status.number[with(http.status.number, order(-freq)), ]
names(ordered.status) <- c("HTTP status code", "freq")
row.names(ordered.status) <- NULL
pie(as.integer(ordered.status$freq ), ordered.status$`HTTP status code`[which(ordered.status$freq > 50)], col = colorRampPalette(brewer.pal(8,"Dark2"))(length(ordered.status$freq)), main = "HTTP status code")
```


De todos los resultados que hemos obtenido, los agrupamos per servidor y mostramos los 20 primeros que contengan más resultados:

```{r servers, echo=FALSE, cache=TRUE}
servers <- plyr::count(unlist(df$server))
servers <- servers[-which(servers$x == "" | servers$x == " " | is.na(servers$x)), ] # Delete empty values
ordered.servers <- servers[with(servers, order(-freq)), ]
names(ordered.servers) <- c("Server", "freq")
row.names(ordered.servers) <- NULL
kable(head(ordered.servers, 20)) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"))
```

Filtramos por el tipo de servidor independientemente de la versión y observamos que la mayoria se concentran en los primeros:
```{r vendors, echo=FALSE, cache=TRUE, warning = FALSE}
vendors <- plyr::count(unlist(df$vendor))
vendors <- vendors[-which(vendors$x == "" | vendors$x == " " | is.na(vendors$x)), ] # Delete empty values
ordered.vendors <- vendors[with(vendors, order(-freq)), ]
names(ordered.vendors) <- c("Vendor", "freq")
row.names(ordered.vendors) <- NULL
kable(head(ordered.vendors, 11)) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"))

pal <- colorFactor(
  palette = c('orange', 'red', 'blue', 'green'),
  domain = c('Apache', 'Microsoft-IIS', 'nginx', 'AkamaiGHost')
)
m <- leaflet() %>%
  addTiles() %>%
  addCircles(lat=subset(df, vendor=='Apache')$lat, lng=subset(df,vendor=='Apache')$lon, color= "red") %>%
  addCircles(lat=subset(df, vendor=='Microsoft-IIS')$lat, lng=subset(df,vendor=='Microsoft-IIS')$lon, color= "blue") %>%
  addCircles(lat=subset(df, vendor=='nginx')$lat, lng=subset(df,vendor=='nginx')$lon, color= "green") %>%
  addCircles(lat=subset(df, vendor=='AkamaiGHost')$lat, lng=subset(df,vendor=='AkamaiGHost')$lon, color= "orange") %>%
  addLegend("bottomright", pal = pal, values = c('Apache', 'Microsoft-IIS', 'nginx', 'AkamaiGHost'), title = "Main server vendors", opacity = 1)
m
```

### Relación con CPE

Buscamos las realiación que hay entre el servidor y versión con un CPE.

A partir de la información del servidor, parseamos los datos del vendor y la versión y obtenemos el CPE correspondiente:
```{r cpes, echo=FALSE, cache=TRUE}
# All cpe22 are actually cpe23, so no need to load them
if (!file.exists(file.path(getwd(), "data", "cpes.rds"))) {
  library(net.security)
  #df$cpe22 <- mapply(x = df$vendor, y = df$version, FUN = function(x, y) GroupAssignmentPackage::get.cpe(x, y, 22))
  df$cpe23 <- mapply(x = df$vendor, y = df$version, FUN = function(x, y) GroupAssignmentPackage::get.cpe(x, y, 23))
} else {
  cpes <- readRDS(file.path(getwd(), "data", "cpes.rds"))
  #df$cpe22 <- mapply(x = df$vendor, y = df$version, FUN = function(x, y) GroupAssignmentPackage::get.cpe(x, y, 22, cpes))
  df$cpe23 <- mapply(x = df$vendor, y = df$version, FUN = function(x, y) GroupAssignmentPackage::get.cpe(x, y, 23, cpes))
}
```

List of most CPE mached
```{r kable_cpe, echo=FALSE, cache=TRUE}
cpes.match <- plyr::count(unlist(df$cpe23))
cpes.match[] <- lapply(cpes.match, function(x) if (is.factor(x)) as.character(x) else {x})
cpes.match <- cpes.match[-which(is.na(cpes.match$x)), ] # Delete empty values
cpes.match <- cpes.match[with(cpes.match, order(-freq)), ]
names(cpes.match) <- c("CPE", "freq")
main.cpes <- head(cpes.match, 50)
row.names(cpes.match) <- NULL
kable(head(cpes.match, 10)) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"))
```


Relación con CVE, para obtener la criticidad de las vulnerabilidades.

```{r cves, echo=FALSE, cache=TRUE}
# Get cves list
if (!file.exists(file.path(getwd(), "data", "cves.rds"))) {
  library(net.security)
  cves <- net.security::GetDataFrame("cves")
} else {
  cves <- readRDS(file.path(getwd(), "data", "cves.rds"))
}

# Match only main cpes.
main.cpes$CVE <- lapply(main.cpes$CPE, function(x) if (!is.na(x)) GroupAssignmentPackage::get.cve(x, cves) else NA)
# Get score for cvss2 and cvss3
main.cpes$score.cvss2 <- lapply(main.cpes$CVE, function(x) GroupAssignmentPackage::get.score(x, 2))
main.cpes$score.cvss3 <- lapply(main.cpes$CVE, function(x) GroupAssignmentPackage::get.score(x, 3))
```
