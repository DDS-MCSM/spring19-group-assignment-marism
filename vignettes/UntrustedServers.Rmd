---
title: "Untrusted Servers"
author: "Martí Barri and Ismael López"
date: "5/25/2019"
output: html_document
---
# Análisis de los servidores que ofrecen servicio por protocolos no seguros

## Resumen
Este informe se centra en realiza un estudio de los tipos de servidores que estan ofreciendo respuesta por protocolos no seguro. 
En la próxima versión de este documento intentaremos relacionar los servidores con sus posibles vulnerabilidades, pero esta versión ha sido desestimado por falta de tiempo.

Todo los datos han sido obtenidos de fuentes publicas y el análisis corresponde a la situación en que nos encontrabamos a día 22-04-2019. 

Adjuntamos el detalle de los enlaces:

- [HTTP GET Responses](https://opendata.rapid7.com/sonar.http/)
- [MaxMind IP Geolocation](https://dev.maxmind.com/geoip/geoip2/geolite2/)

# Objetivos 

El objetivo de este análisis se centra en responder las siguientes preguntas:

- ¿Dónde estan ubicados los servidores que estan dando servicio por procolos no seguros?
- ¿Qué tipo de servidores son?
- ¿Los paises desarllados son más seguros a nivel de seguridad informatica que los subdesarollados?


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
# Definimos el directorio de trabajo

#knitr::opts_knit$set(root.dir = "/home/marti/Desktop/master_cybersecurity/4_Data_Driven_Security/LAB/spring19-group-assignment-marism")
knitr::opts_knit$set(root.dir = "/Users/ismael/Documents/MASTER/PRACTICA/spring19-group-assignment-marism")
verbose <- FALSE
```


```{r load_packages, echo = FALSE, cache = TRUE, message=FALSE, include=FALSE}
# Required Packages
pkg <- c("R.utils", "iptools", "parallel", "dplyr", "jsonlite", "GroupAssignmentPackage", "mapproj", "kableExtra")

# Instalar paquetes que no esten instalados
new.pkg <- pkg[!(pkg %in% installed.packages())]
if (length(new.pkg)) 
{
    install.packages(new.pkg)  
}
# Load packages
lapply(pkg, require, character.only = TRUE)
```

## Análisis

Podemos descargar el fichero directamente de la web, muestras del puerto 80, no obstante este fichero descomprimido ocupa 170,70 GB y tardariamos horas en porderlo procesar integramente. Por ello hemos considerado trabajar con una parte significativa de las muestras.

Para generar nuestro archivo de pruebas realizamos las siguentes comando:

`user@linux$ head -n 5000  2019-04-22-1555944117-http_get_80.json > sample80_5K.json`

Convertimos el fichero json en un dataframe, utilizando los siguiente comandos:

```{r sample, echo=TRUE, eval=FALSE}
sample.file <- file.path(getwd(), "data", "sample80_5K.json")
lines <- readLines(sample.file)
df.raw <- plyr::ldply(lines, function(x) as.data.frame(jsonlite::fromJSON(x), stringsAsFactors = FALSE))
saveRDS(object = df.raw, file = file.path(getwd(), "data", "df_http_get_80_raw_5k.rds"))
```

Si observamos detenidamente el fichero que con las muestras, podemos apreciar que la columan "data" tiene los datos cifrados en base64 y que algunas columnas tienen el contedido duplicado o no nos aporta ninguna información relevante para el analisis que queremos realizar. 

Por ello descartamos la informacion de la columna ("host", "vhost" y "path").

La información del dataframe que nos interesa es la siguiente:

```{r load_response_data, echo = FALSE, cache = TRUE}
df.raw <- readRDS(file.path(getwd(), "data", "df_http_get_80_raw_5k.rds"))
df.raw[which(names(df.raw) == "host")] <- NULL
df.raw[which(names(df.raw) == "vhost")] <- NULL
df.raw[which(names(df.raw) == "path")] <- NULL
str(df.raw)
```

Procedemos a cargar o descargar el fichero Maxmind, con los siguiente comandos:

```{r load_maxmind, echo = TRUE, cache = TRUE}
# Get maxmind
if ((!file.exists(file.path(getwd(), "data", "GeoLite2-City-Blocks-IPv4.csv")))){
  df.maxmind <- GroupAssignmentPackage::get.maxmind(verbose)
} else {
  maxmind.source <- file.path(getwd(), "data", "GeoLite2-City-Blocks-IPv4.csv")
  df.maxmind <- read.csv(maxmind.source, stringsAsFactors = FALSE)
}
# Expanding MaxMind network ranges
df.maxmind <- cbind(df.maxmind, iptools::range_boundaries(df.maxmind$network))
df.maxmind$rowname <- as.integer(row.names(df.maxmind))
```

En el fichero Maxmind obtenemos geolocalización de un rango de IP y por lado en el fichero de df_http_get_80_raw_5k.rds tenemos una única IP, el objetivo de este apartado es conseguir la geolocalización de esa IP. 

Para poder comparar en que rango de IP cae esa IP y obtener la geolocalización, convertimos las IP en una variable numérica y vamos iterando hasta encontrar el rango en que el  IP es mayor o igual al valor máximo.


El objetivo es saber cada IP de las muestras que 



El contenido del fichero Maxmind, contienen la siguiente información:

```{r geolocate, echo = FALSE, cache = TRUE}
if (!file.exists(file.path(getwd(), "data", "df_http_get_80_raw_geo_5k.rds"))){
  df.raw <- GroupAssignmentPackage::add.numeric.ip(df.raw, "ip")
  df.raw.geo <- GroupAssignmentPackage::geolocate.http.responses(df.maxmind, df.raw)
} else {
  df.raw.geo <- readRDS(file.path(getwd(), "data", "df_http_get_80_raw_geo_5k.rds"))
}
rm(df.raw)
str(df.raw.geo)
```


Una vez aplicado todo el procesamiento y tratamiento de datos, es hora de mostrar los resultados. 

Representando esta información con un gráfico de dispersión podemos ver que la distribución se asemeja notablemente al mapamundi:
```{r dispersion_coord, echo = FALSE, cache = TRUE, fig.align = 'center'}
library(ggplot2)
# Creamos ggplot con los datos de symantec
gg <- ggplot(data = df.raw.geo, aes(x = longitude, y = latitude)) 
# definimos la grafica por puntos con transparencia
gg <- gg + geom_point(size=1, color="#000099", alpha=1/40) 
# Titulos de los ejes
gg <- gg + xlab("Longitud") + ylab("Latitud")
# aplicamos el tema simple
gg <- gg + theme_bw() 
# tarda un poco pq son 800.000 puntos
print(gg)
```

Añadimos información sobre paises y sus fronteras para enriquecer el mapa.
```{r map_simple, echo=FALSE, cache=TRUE, fig.align='center'}
world <- map_data("world")
# Quitamos el continete Antarctico ya que no aporta informaci?n
# No es nada personal con los pinguinos...
world <- subset(world, world$region!="Antarctica")

gg <- ggplot(data=world, aes(x=long, y=lat))
gg <- gg + geom_path(aes(group=group), colour="gray70")
# La definici?n de la proyeccion representa la "curvatura" del mapa
gg <- gg + coord_map("mercator", xlim=c(-200, 200))
# A?adimos una capa al mapa con la informacion
gg <- gg + geom_point(data = df.raw.geo, aes(longitude, latitude), 
                      colour="#000099", alpha=1/40, size=1)
# Eliminamos texto y le damos un poco de color
gg <- gg + theme(text=element_blank(), 
                 axis.ticks=element_blank(),
                 panel.grid=element_blank(),
                 panel.background=element_rect(color="gray50",
                                               fill="white"))
print(gg)
```


Después de ver la localización de los servidores, vamos a decodificar los datos y a parsear los headers para obtener información más detallada.
```{r parse_headers, echo=FALSE, cache=TRUE}
df <- GroupAssignmentPackage::parse.headers(df.raw.geo)
```

Podemos ver las versiones utilizadas de HTTP
```{r kable, echo=FALSE, cache=TRUE}
kable(plyr::count(df$version)) %>%
  kable_styling(bootstrap_options = c("striped", "hover"))
```

En azul la versión 1.0 y en rojo la 1.1
```{r map_version, echo=FALSE, cache=TRUE, fig.align='center'}
world <- map_data("world")
# Quitamos el continete Antarctico ya que no aporta informaci?n
# No es nada personal con los pinguinos...
world <- subset(world, world$region!="Antarctica")

gg <- ggplot(data=world, aes(x=long, y=lat))
gg <- gg + geom_path(aes(group=group), colour="gray70")
# La definici?n de la proyeccion representa la "curvatura" del mapa
gg <- gg + coord_map("mercator", xlim=c(-200, 200))
# Añadimos una capa al mapa con la informacion
gg <- gg + geom_point(data = dplyr::filter(df, grepl('HTTP/1.0', version)), aes(longitude, latitude),
                      colour="blue", alpha=1/40, size=1)

gg <- gg + geom_point(data = dplyr::filter(df, grepl('HTTP/1.1', version)), aes(longitude, latitude),
                      colour="red", alpha=1/40, size=1)
# Eliminamos texto y le damos un poco de color
gg <- gg + theme(text=element_blank(), 
                 axis.ticks=element_blank(),
                 panel.grid=element_blank(),
                 panel.background=element_rect(color="gray50",
                                               fill="white"))
print(gg)
```

```{r servers, echo=FALSE, cache=TRUE}
servers <- plyr::count(unlist(df$server))
ordered_servers <- servers[with(servers, order(-freq)), ]
head(ordered_servers, 20)
```

```{r main_servers, echo=FALSE, cache=TRUE}
apache <- servers[grep("Apache", servers$x), ]
sum_apache <- sum(apache$freq)
nginx <- servers[grep("nginx", servers$x), ]
sum_nginx <- sum(nginx$freq)
win <- servers[grep("Microsoft", servers$x), ]
sum_win <- sum(win$freq)
```

Get CVES from net.security package
```
cves <- net.security::GetDataFrame("cves")
cves.apache <- cves[grep("apache", cves$affects), ]
```
